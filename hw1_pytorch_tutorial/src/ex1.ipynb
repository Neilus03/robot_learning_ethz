{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9f8a943",
      "metadata": {},
      "source": [
        "# Exercise 1: Tensor basics \n",
        "In this exercise you will learn the basics of tensor creation, manipulation, indexing, broadcasting, vectorization, einsum, and attention masking fundamentals. These basics are important for understanding any complex implementation later on so make sure you understand them well.\n",
        "\n",
        "**To complete this exercise fill in all TODOs in the functions below.** \n",
        "\n",
        "Make sure to check the output of your function and whether or not it fulfills the requirements outlined in the function definition. Do NOT change the function signature or name since we will be running checks on your functions during grading.\n",
        "\n",
        "### Shape legend used in this notebook\n",
        "- `B`: batch size\n",
        "- `T`: sequence length / time\n",
        "- `D`: feature dimension\n",
        "- `H`: number of attention heads\n",
        "- `Dh`: per-head feature dimension\n",
        "\n",
        "### Debugging tip: what to print\n",
        "When you get a shape error, print:\n",
        "- `x.shape`, `x.dtype`, `x.device`\n",
        "- `x.is_contiguous()` (important for `view`)\n",
        "For masks also print:\n",
        "- `mask.shape`, `mask.dtype`, `mask.sum()` and a small slice like `mask[0, :10]`\n",
        "\n",
        "### Reproducibility tip: seeding in PyTorch\n",
        "Many operations in deep learning involve randomness (e.g., initializing model weights, shuffling data, dropout, random augmentations).\n",
        "**Seeding** sets the starting state of PyTorch’s random number generator so that these random choices become **repeatable**.\n",
        "\n",
        "- If you set the same seed and run the same code again, you should get the same *random* tensors / initial weights.\n",
        "- If you don’t set a seed, results can vary between runs.\n",
        "\n",
        "Common usage: `torch.manual_seed(seed)`\n",
        "\n",
        "Note: even with fixed seeds, some GPU operations can still be non-deterministic due to performance optimizations. For this assignment, seeding is mainly to make debugging easier and to ensure everyone can reproduce the same intermediate results. If you are given a seed, make sure to use it when creating tensors or performing other operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038d374d",
      "metadata": {},
      "source": [
        "## Tensor creation\n",
        "This warmup exercise teaches you how to create tensors with different shapes and values. A few details about tensor creation that are good to know:\n",
        "- `torch.tensor([...])` infers dtype from Python values (ints → integer tensor, floats → float tensor).\n",
        "- `torch.arange(start, end)` is **end-exclusive**.\n",
        "- `torch.linspace(start, end, steps)` is **end-inclusive**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4c4db00a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\neild\\Miniconda3\\envs\\robot_learning_env\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:283: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b781b9ab",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_tensor(data, dtype: torch.dtype | None = None, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\" Create a tensor from Python data (list/tuple/nested lists). \"\"\"\n",
        "    return torch.tensor(data, dtype=dtype, device=device)\n",
        "\n",
        "x = make_tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1b76bc69",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_zeros(shape: Sequence[int], dtype: torch.dtype | None = None, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\"Create a tensor filled with zeros.\"\"\"\n",
        "    return torch.zeros(shape, dtype=dtype,device=device)\n",
        "\n",
        "z = make_zeros((2, 3), dtype=torch.float64)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "758dfb6c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_ones_like(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Create a tensor of ones with the same shape, dtype, and device as x. \"\"\"\n",
        "    return torch.ones_like(x)\n",
        "\n",
        "base = torch.randn(2, 3, dtype=torch.float32)\n",
        "ones = make_ones_like(base)\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b764cf52",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 2, 4])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_arange(start: int, end: int, step: int = 1, dtype: torch.dtype | None = None, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\"Create a 1D tensor containing values [start, start+step, ..., < end].\"\"\"\n",
        "    return torch.arange(start, end, step, dtype=dtype, device=device)\n",
        "\n",
        "ar = make_arange(0, 5, 2, dtype=torch.int64)\n",
        "ar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0fd936a5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_linspace(start: float, end: float, steps: int, dtype: torch.dtype | None = None, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\"Create a 1D tensor with evenly spaced values from start to end (inclusive).\"\"\"\n",
        "    return torch.linspace(start, end, steps, dtype=dtype, device=device)\n",
        "\n",
        "ls = make_linspace(0.0, 1.0, steps=5, dtype=torch.float32)\n",
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "60f092d9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1115,  0.1204, -0.3696],\n",
              "        [-0.2404, -1.1969,  0.2093]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_randn(shape: Sequence[int], seed: int | None = None, dtype: torch.dtype | None = None, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\"Create a tensor filled with values from a standard normal distribution.\"\"\"\n",
        "    return torch.randn(shape, generator=torch.Generator(device=device if device else 'cpu').manual_seed(seed), dtype=dtype, device=device)\n",
        "a = make_randn((2, 3), seed=123, dtype=torch.float32)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5c6eb09a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Casted: tensor([1., 2., 3.]), dtype: torch.float32\n"
          ]
        }
      ],
      "source": [
        "def cast_dtype_and_move(x: torch.Tensor, device: torch.device, dtype: torch.dtype) -> torch.Tensor:\n",
        "    \"\"\"Convert tensor dtype and move to device.\"\"\"\n",
        "    return x.to(device=device, dtype=dtype)\n",
        "\n",
        "casted = cast_dtype_and_move(torch.tensor([1, 2, 3]), torch.device(\"cpu\"), torch.float32)\n",
        "print(f\"Casted: {casted}, dtype: {casted.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c98566de",
      "metadata": {},
      "source": [
        "## Shape manipulation\n",
        "Now that we covered the basic tensor creation schemes, we want to focus on shape manipulation. Understanding the difference between these mechanisms is key for building larger systems and many people still get it wrong. \n",
        "The core ideas to understand are:\n",
        "- **Contiguous tensors** store data in a single, row-major memory layout.\n",
        "- Many ops (especially slicing like `x[:, ::2]`, `transpose`, `permute`) often create **non-contiguous** tensors (no copy but different strides).\n",
        "- `view(...)` is **zero-copy** but typically requires **contiguous** memory → may throw an error.\n",
        "- `reshape(...)` tries to return a view, but if the tensor is non-contiguous it will **allocate/copy**.\n",
        "- `contiguous()` forces a contiguous copy when the tensor isn’t contiguous.\n",
        "\n",
        "If you *need* a view after reordering dims: call `x = x.contiguous()` first (this makes a contiguous copy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "6def6846",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before reshaping: tensor([0, 1, 2, 3, 4, 5]), shape: torch.Size([6])\n",
            "After reshaping: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]]), shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "def reshape_tensor(x: torch.Tensor, new_shape: Sequence[int]) -> torch.Tensor:\n",
        "    \"\"\"Reshape tensor to new_shape (may return a view or a copy).\"\"\"\n",
        "    return torch.reshape(x, new_shape)\n",
        "\n",
        "x = torch.arange(6)\n",
        "y = reshape_tensor(x, (2, 3))\n",
        "print(f\"Before reshaping: {x}, shape: {x.shape}\")\n",
        "print(f\"After reshaping: {y}, shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4b508ceb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before view: tensor([0, 1, 2, 3, 4, 5]), shape: torch.Size([6])\n",
            "After view: tensor([[0, 1, 2],\n",
            "        [3, 4, 5]]), shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "def view_tensor(x: torch.Tensor, new_shape: Sequence[int]) -> torch.Tensor:\n",
        "    \"\"\"View tensor as new_shape (requires contiguous memory and doesn't allocate new memory for the tensor data).\"\"\"\n",
        "    return x.view(new_shape)\n",
        "\n",
        "y_view = view_tensor(x, (2, 3))\n",
        "print(f\"Before view: {x}, shape: {x.shape}\")\n",
        "print(f\"After view: {y_view}, shape: {y_view.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "59fe1ed1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before flattening: torch.Size([2, 3, 4])\n",
            "After flattening: torch.Size([2, 12])\n"
          ]
        }
      ],
      "source": [
        "def flatten_from_dim(x: torch.Tensor, start_dim: int = 0) -> torch.Tensor:\n",
        "    \"\"\"Flatten a tensor starting from start_dim into a single dimension.\"\"\"\n",
        "    return x.flatten(start_dim)\n",
        "\n",
        "x2 = torch.randn(2, 3, 4)\n",
        "flat = flatten_from_dim(x2, start_dim=1)\n",
        "print(f\"Before flattening: {x2.shape}\")\n",
        "print(f\"After flattening: {flat.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c733b377",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before adding singleton dim: torch.Size([5, 7])\n",
            "After adding singleton dim at dim=1: torch.Size([5, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "def add_singleton_dim(x: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "    \"\"\"Insert a size-1 dimension at position dim.\"\"\"\n",
        "    return x.unsqueeze(dim)\n",
        "\n",
        "x3 = torch.randn(5, 7)\n",
        "x3s = add_singleton_dim(x3, dim=1)\n",
        "print(f\"Before adding singleton dim: {x3.shape}\")\n",
        "print(f\"After adding singleton dim at dim=1: {x3s.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "9552b216",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before removing singleton dim: torch.Size([2, 1, 3])\n",
            "After removing singleton dim at dim=1: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "def remove_singleton_dims(x: torch.Tensor, dim: int | None = None) -> torch.Tensor:\n",
        "    \"\"\"Remove size-1 dimensions.\"\"\"\n",
        "    if dim is None:\n",
        "        return x.squeeze()\n",
        "    return x.squeeze(dim)\n",
        "\n",
        "x4 = torch.randn(2, 1, 3)\n",
        "x4s = remove_singleton_dims(x4)\n",
        "print(f\"Before removing singleton dim: {x4.shape}\")\n",
        "print(f\"After removing singleton dim at dim=1: {x4s.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2ad8f628",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before transpose: torch.Size([2, 3, 4])\n",
            "After transpose: torch.Size([2, 4, 3])\n"
          ]
        }
      ],
      "source": [
        "def transpose_last_two(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Swap the last two dimensions of x.\"\"\"\n",
        "    return x.transpose(-2, -1)\n",
        "\n",
        "x6 = torch.randn(2, 3, 4)\n",
        "x6t = transpose_last_two(x6)\n",
        "print(f\"Before transpose: {x6.shape}\")\n",
        "print(f\"After transpose: {x6t.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "a26228c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before permute: torch.Size([8, 32, 32, 3])\n",
            "After permute: torch.Size([8, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "def permute_bhwc_to_bchw(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Convert (B, H, W, C) tensor into (B, C, H, W).\"\"\"\n",
        "    return x.permute(0, 3, 1, 2)\n",
        "\n",
        "x7 = torch.randn(8, 32, 32, 3)\n",
        "x7p = permute_bhwc_to_bchw(x7)\n",
        "print(f\"Before permute: {x7.shape}\")\n",
        "print(f\"After permute: {x7p.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "bfd919ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before making contiguous - is_contiguous: False\n",
            "Shape: torch.Size([4, 3])\n",
            "After making contiguous - is_contiguous: True\n",
            "Shape: torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "def make_contiguous(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Check if tensor is contiguous and if not make contiguous.\"\"\"\n",
        "    if not x.is_contiguous():\n",
        "        return x.contiguous()\n",
        "    return x\n",
        "\n",
        "x8 = torch.randn(4, 6)[:, ::2]\n",
        "print(f\"Before making contiguous - is_contiguous: {x8.is_contiguous()}\")\n",
        "print(f\"Shape: {x8.shape}\")\n",
        "x8c = make_contiguous(x8)\n",
        "print(f\"After making contiguous - is_contiguous: {x8c.is_contiguous()}\")\n",
        "print(f\"Shape: {x8c.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76616564",
      "metadata": {},
      "source": [
        "## Indexing\n",
        "Now that we know how to create tensors and manipulate them we need to understand how we can extract certain components from them using indexing. \n",
        "- Basic slicing (`x[a:b]`) returns a view when possible.\n",
        "- “Fancy” indexing (lists/tensors of indices) usually allocates a new tensor.\n",
        "- In-place vs out-of-place matters: if a function says “return a copy, leave the input unchanged”, you need `clone()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "00724376",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "Sliced rows [1:3]:\n",
            "tensor([[3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "def slice_rows(x: torch.Tensor, start: int, end: int) -> torch.Tensor:\n",
        "    \"\"\"Slice rows in a 2D tensor: x[start:end, :].\"\"\"\n",
        "    return x[start:end]\n",
        "\n",
        "x = torch.arange(12).reshape(4, 3)\n",
        "rows = slice_rows(x, 1, 3)\n",
        "print(f\"Original tensor:\\n{x}\")\n",
        "print(f\"\\nSliced rows [1:3]:\\n{rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "703bcf10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "Selected columns [0, 2]:\n",
            "tensor([[ 0,  2],\n",
            "        [ 3,  5],\n",
            "        [ 6,  8],\n",
            "        [ 9, 11]])\n"
          ]
        }
      ],
      "source": [
        "def select_columns(x: torch.Tensor, cols: Sequence[int]) -> torch.Tensor:\n",
        "    \"\"\"Select specific columns from a 2D tensor.\"\"\"\n",
        "    return x[:, cols]\n",
        "\n",
        "cols = select_columns(x, [0, 2])\n",
        "print(f\"Original tensor:\\n{x}\\n\")\n",
        "print(f\"Selected columns [0, 2]:\\n{cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c08ff8e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\n",
            "Diagonal:\n",
            "tensor([1, 4])\n"
          ]
        }
      ],
      "source": [
        "def get_diagonal(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Get the diagonal of a 2D tensor.\"\"\"\n",
        "    return x.diagonal()\n",
        "\n",
        "d = get_diagonal(torch.tensor([[1, 2], [3, 4]]))\n",
        "print(f\"Original:\\n{torch.tensor([[1, 2], [3, 4]])}\\n\")\n",
        "print(f\"Diagonal:\\n{d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "97eff27e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "\n",
            "After setting [0, 1] to 5.0:\n",
            "tensor([[0., 5.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "def set_subtensor(x: torch.Tensor, row_idx: int, col_idx: int, value: float) -> torch.Tensor:\n",
        "    \"\"\"Return a copy of x where x[row_idx, col_idx] is set to value.\"\"\"\n",
        "    result = x.clone()\n",
        "    result[row_idx, col_idx] = value\n",
        "    return result\n",
        "\n",
        "base = torch.zeros(2, 2)\n",
        "out = set_subtensor(base, 0, 1, 5.0)\n",
        "print(f\"Original tensor:\\n{base}\\n\")\n",
        "print(f\"After setting [0, 1] to 5.0:\\n{out}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c92ac1be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor:\n",
            "tensor([[10, 11],\n",
            "        [20, 21],\n",
            "        [30, 31]])\n",
            "\n",
            "Row indices: tensor([2, 0])\n",
            "\n",
            "Gathered rows:\n",
            "tensor([[30, 31],\n",
            "        [10, 11]])\n"
          ]
        }
      ],
      "source": [
        "def gather_rows(x: torch.Tensor, row_indices: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Gather (concat) rows from x using row_indices.\"\"\"\n",
        "    return x[row_indices]\n",
        "\n",
        "x2 = torch.tensor([[10, 11], [20, 21], [30, 31]])\n",
        "idx = torch.tensor([2, 0])\n",
        "gathered = gather_rows(x2, idx)\n",
        "print(f\"Original tensor:\\n{x2}\\n\")\n",
        "print(f\"Row indices: {idx}\\n\")\n",
        "print(f\"Gathered rows:\\n{gathered}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0cd0b7",
      "metadata": {},
      "source": [
        "## Broadcasting and reducing\n",
        "Now we're covering a pytorch mechanism that lets you apply elementwise ops without using python loops. It's important to understand how it works to trace your shapes in complicated systems. The broadcasting rules to know are:\n",
        "- Dimensions align from the **right**.\n",
        "- A dimension can broadcast if it’s equal or one of them is **1**.\n",
        "\n",
        "### Reduction ops and `keepdim`\n",
        "\n",
        "When you reduce over a dimension (e.g. `sum`, `mean`, `max`), PyTorch can either:\n",
        "\n",
        "- **remove** the reduced dimension (`keepdim=False`, default), or\n",
        "- **keep** it as size 1 (`keepdim=True`)\n",
        "\n",
        "Keeping the dimension is often helpful because it makes broadcasting back “just work”.\n",
        "\n",
        "#### Shape diagram examples\n",
        "\n",
        "Assume `x` has shape `(B, T, D)`:\n",
        "\n",
        "**Sum over time**\n",
        "- `x.sum(dim=1)` → shape `(B, D)`\n",
        "- `x.sum(dim=1, keepdim=True)` → shape `(B, 1, D)`\n",
        "\n",
        "**Mean over features**\n",
        "- `x.mean(dim=2)` → shape `(B, T)`\n",
        "- `x.mean(dim=2, keepdim=True)` → shape `(B, T, 1)`\n",
        "\n",
        "#### Why `keepdim=True` helps with broadcasting\n",
        "\n",
        "Example: center `x` by subtracting the mean over `T`\n",
        "\n",
        "- If `m = x.mean(dim=1)` has shape `(B, D)`, then `x - m` **fails** (shapes `(B,T,D)` and `(B,D)` don't align).\n",
        "- If `m = x.mean(dim=1, keepdim=True)` has shape `(B,1,D)`, then `x - m` **works** via broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "541c7cd5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Sum over dim 1: tensor([3., 3.])\n",
            "Shape: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "def sum_over_dim(x: torch.Tensor, dim: int, keepdim: bool = False) -> torch.Tensor:\n",
        "    \"\"\"Sum tensor values along dimension dim.\"\"\"\n",
        "    return x.sum(dim=dim, keepdim=keepdim)\n",
        "\n",
        "x = torch.ones(2, 3)\n",
        "y = sum_over_dim(x, dim=1)\n",
        "print(\"x:\",x)\n",
        "print(f\"Sum over dim 1: {y}\")\n",
        "print(f\"Shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "cd78da22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x2: tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Mean over dim 0: tensor([2., 3.])\n",
            "Shape: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "def mean_over_dim(x: torch.Tensor, dim: int, keepdim: bool = False) -> torch.Tensor:\n",
        "    \"\"\"Mean along dimension dim.\"\"\"\n",
        "    return x.mean(dim=dim, keepdim=keepdim)\n",
        "\n",
        "x2 = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "y2 = mean_over_dim(x2, dim=0)\n",
        "print(\"x2:\", x2)\n",
        "print(f\"Mean over dim 0: {y2}\")\n",
        "print(f\"Shape: {y2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "eec32da4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input tensor:\n",
            "tensor([[1., 5.],\n",
            "        [3., 2.]])\n",
            "Max values over dim=1: tensor([5., 3.])\n",
            "Argmax indices over dim=1: tensor([1, 0])\n"
          ]
        }
      ],
      "source": [
        "def max_over_dim(x: torch.Tensor, dim: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Max values and argmax indices along dimension dim.\"\"\"\n",
        "    values, indices = x.max(dim=dim)\n",
        "    return values, indices\n",
        "\n",
        "x3 = torch.tensor([[1.0, 5.0], [3.0, 2.0]])\n",
        "values, idx = max_over_dim(x3, dim=1)\n",
        "print(f\"Input tensor:\\n{x3}\")\n",
        "print(f\"Max values over dim=1: {values}\")\n",
        "print(f\"Argmax indices over dim=1: {idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "34c7d6cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input tensor for argmax_over_dim:\n",
            "tensor([[1., 5.],\n",
            "        [3., 2.]])\n",
            "Argmax indices over dim=1: tensor([1, 0])\n"
          ]
        }
      ],
      "source": [
        "def argmax_over_dim(x: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "    \"\"\"Argmax indices along dimension dim.\"\"\"\n",
        "    return x.argmax(dim=dim)\n",
        "\n",
        "idx2 = argmax_over_dim(x3, dim=1)\n",
        "print(f\"Input tensor for argmax_over_dim:\\n{x3}\")\n",
        "print(f\"Argmax indices over dim=1: {idx2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "5acbc839",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input tensor x4:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "Vector v: tensor([10., 20.])\n",
            "Result of broadcast_add_vector(x4, v):\n",
            "tensor([[10., 20.],\n",
            "        [10., 20.],\n",
            "        [10., 20.]])\n"
          ]
        }
      ],
      "source": [
        "def broadcast_add_vector(x: torch.Tensor, v: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Add a vector v to each row of a 2D tensor x using broadcasting.\"\"\"\n",
        "    return x + v\n",
        "\n",
        "x4 = torch.zeros(3, 2)\n",
        "v = torch.tensor([10.0, 20.0])\n",
        "y4 = broadcast_add_vector(x4, v)\n",
        "print(f\"Input tensor x4:\\n{x4}\")\n",
        "print(f\"Vector v: {v}\")\n",
        "print(f\"Result of broadcast_add_vector(x4, v):\\n{y4}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f2629b",
      "metadata": {},
      "source": [
        "## Vectorization\n",
        "We want to avoid slow (due to per-iteration overhead) python loops as much as possible and pytorch gives us many tools to avoid it. We cover these basics:\n",
        "- `cat` vs `stack` (concatenate existing dims vs create a new dim)\n",
        "- `repeat` vs `expand`\n",
        "- `scatter_add` / `index_add` for accumulation\n",
        "- `where` for conditional selection\n",
        "\n",
        "### `expand` vs `repeat`\n",
        "\n",
        "- `repeat(...)` **copies** data → larger tensor with independent storage.\n",
        "- `expand(...)` **does not copy** data → it creates a *view* with clever strides.\n",
        "\n",
        "This has two important implications:\n",
        "\n",
        "1) `expand` only works when expanding a **size-1 dimension** (broadcasting a singleton).\n",
        "2) The expanded tensor may have **many positions pointing to the same memory**.  \n",
        "   Modifying the expanded tensor can therefore produce surprising results (multiple rows change).\n",
        "\n",
        "Rule of thumb:\n",
        "- Use `expand` for read-only broadcasting.\n",
        "- Use `repeat` if you truly need independent copies.\n",
        "\n",
        "\n",
        "NOTE: We implore you to write your own quick checks from now on for calling the functions and checking their output. As before you are still required to fill in the TODOs in each function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "ba4d9f18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First tensor c1:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Second tensor c2:\n",
            "tensor([[5, 6]])\n",
            "Concatenated along dim=0:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "def concat_tensors(tensors: Sequence[torch.Tensor], dim: int = 0) -> torch.Tensor:\n",
        "    \"\"\"Concatenate tensors along dim. NOTE: This will always allocate new memory\"\"\"\n",
        "    return torch.cat(list(tensors), dim=dim)\n",
        "\n",
        "# Quick check for concat_tensors\n",
        "c1 = torch.tensor([[1, 2], [3, 4]])\n",
        "c2 = torch.tensor([[5, 6]])\n",
        "concatenated = concat_tensors([c1, c2], dim=0)\n",
        "print(f\"First tensor c1:\\n{c1}\")\n",
        "print(f\"Second tensor c2:\\n{c2}\")\n",
        "print(f\"Concatenated along dim=0:\\n{concatenated}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "81e197f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First tensor s1: tensor([1, 2])\n",
            "Second tensor s2: tensor([3, 4])\n",
            "Stacked along dim=0:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "def stack_tensors(tensors: Sequence[torch.Tensor], dim: int = 0) -> torch.Tensor:\n",
        "    \"\"\"Stack tensors along a new dimension dim.\"\"\"\n",
        "    return torch.stack(list(tensors), dim=dim)\n",
        "\n",
        "# Quick check for stack_tensors\n",
        "s1 = torch.tensor([1, 2])\n",
        "s2 = torch.tensor([3, 4])\n",
        "stacked = stack_tensors([s1, s2], dim=0)\n",
        "print(f\"First tensor s1: {s1}\")\n",
        "print(f\"Second tensor s2: {s2}\")\n",
        "print(f\"Stacked along dim=0:\\n{stacked}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "50b20f35",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor r:\n",
            "tensor([[1, 2]])\n",
            "Repeated with repeats=(2, 3):\n",
            "tensor([[1, 2, 1, 2, 1, 2],\n",
            "        [1, 2, 1, 2, 1, 2]])\n"
          ]
        }
      ],
      "source": [
        "def repeat_tensor(x: torch.Tensor, repeats: Sequence[int]) -> torch.Tensor:\n",
        "    \"\"\"Repeat tensor along each dimension.\"\"\"\n",
        "    return x.repeat(*repeats)\n",
        "\n",
        "# Quick check for repeat_tensor\n",
        "r = torch.tensor([[1, 2]])\n",
        "repeated = repeat_tensor(r, (2, 3))\n",
        "print(f\"Original tensor r:\\n{r}\")\n",
        "print(f\"Repeated with repeats=(2, 3):\\n{repeated}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "b7a34fd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor e:\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "Expanded to size (3, 4):\n",
            "tensor([[1, 1, 1, 1],\n",
            "        [2, 2, 2, 2],\n",
            "        [3, 3, 3, 3]])\n"
          ]
        }
      ],
      "source": [
        "def expand_tensor(x: torch.Tensor, *sizes: int) -> torch.Tensor:\n",
        "    \"\"\"Expand tensor to a larger size without copying data.(Sizes can be -1 to keep original dimension.)\"\"\"\n",
        "    return x.expand(*sizes)\n",
        "\n",
        "# Quick check for expand_tensor\n",
        "e = torch.tensor([[1], [2], [3]])\n",
        "expanded = expand_tensor(e, 3, 4)\n",
        "print(f\"Original tensor e:\\n{e}\")\n",
        "print(f\"Expanded to size (3, 4):\\n{expanded}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "a5120093",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor c:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Cumulative sum along dim=0:\n",
            "tensor([[1, 2, 3],\n",
            "        [5, 7, 9]])\n",
            "Cumulative sum along dim=1:\n",
            "tensor([[ 1,  3,  6],\n",
            "        [ 4,  9, 15]])\n"
          ]
        }
      ],
      "source": [
        "def cumsum_over_dim(x: torch.Tensor, dim: int = 0) -> torch.Tensor:\n",
        "    \"\"\"Cumulative sum along dim.\"\"\"\n",
        "    return x.cumsum(dim)\n",
        "\n",
        "# Quick check for cumsum_over_dim\n",
        "c = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "cumsum_dim0 = cumsum_over_dim(c, dim=0)\n",
        "cumsum_dim1 = cumsum_over_dim(c, dim=1)\n",
        "print(f\"Original tensor c:\\n{c}\")\n",
        "print(f\"Cumulative sum along dim=0:\\n{cumsum_dim0}\")\n",
        "print(f\"Cumulative sum along dim=1:\\n{cumsum_dim1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "efa8c018",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mask:\n",
            "tensor([[ True, False],\n",
            "        [False,  True]])\n",
            "Tensor a:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Tensor b:\n",
            "tensor([[0, 0],\n",
            "        [0, 0]])\n",
            "where_select result:\n",
            "tensor([[1, 0],\n",
            "        [0, 4]])\n"
          ]
        }
      ],
      "source": [
        "def where_select(mask: torch.Tensor, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Elementwise select: return a where mask is True else b. mask must be broadcastable to a and b.\"\"\"\n",
        "    return torch.where(mask, a, b)\n",
        "\n",
        "# Quick check for where_select\n",
        "mask = torch.tensor([[True, False], [False, True]])\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.zeros_like(a)\n",
        "result = where_select(mask, a, b)\n",
        "print(f\"Mask:\\n{mask}\")\n",
        "print(f\"Tensor a:\\n{a}\")\n",
        "print(f\"Tensor b:\\n{b}\")\n",
        "print(f\"where_select result:\\n{result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "28a2eed9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices: tensor([0, 2, 1, 3])\n",
            "One-hot encoding:\n",
            "tensor([[1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1.]])\n",
            "\n",
            "2D Indices:\n",
            "tensor([[0, 1],\n",
            "        [2, 0]])\n",
            "One-hot encoding (2D):\n",
            "tensor([[[1., 0., 0.],\n",
            "         [0., 1., 0.]],\n",
            "\n",
            "        [[0., 0., 1.],\n",
            "         [1., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "def one_hot(indices: torch.Tensor, num_classes: int, dtype: torch.dtype | None = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Create one-hot encodings.\n",
        "    Output is a tensor of the same shape as indices with an added dimension of size num_classes at the end,\n",
        "    where the value along that dimension is 1 if it matches the index and 0 otherwise.\n",
        "\n",
        "    Shapes:\n",
        "    - indices: (...,) integer tensor\n",
        "    Return:\n",
        "    - out: (..., num_classes)\n",
        "\n",
        "    Requirements:\n",
        "    - Must work for arbitrary leading shape.\n",
        "    - No Python loops.\n",
        "    \"\"\"\n",
        "    # Create a tensor of zeros with shape (*indices.shape, num_classes)\n",
        "    out = torch.zeros(*indices.shape, num_classes, dtype=dtype if dtype is not None else torch.float32, device=indices.device)\n",
        "    # Use scatter to set 1s at the appropriate positions\n",
        "    # We need to add a dimension to indices to match the output shape\n",
        "    out.scatter_(-1, indices.unsqueeze(-1), 1)\n",
        "    return out\n",
        "\n",
        "# Quick check for one_hot\n",
        "indices = torch.tensor([0, 2, 1, 3])\n",
        "one_hot_result = one_hot(indices, num_classes=4)\n",
        "print(f\"Indices: {indices}\")\n",
        "print(f\"One-hot encoding:\\n{one_hot_result}\")\n",
        "\n",
        "# Test with 2D indices\n",
        "indices_2d = torch.tensor([[0, 1], [2, 0]])\n",
        "one_hot_2d = one_hot(indices_2d, num_classes=3)\n",
        "print(f\"\\n2D Indices:\\n{indices_2d}\")\n",
        "print(f\"One-hot encoding (2D):\\n{one_hot_2d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6953837c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Values: tensor([1., 2., 3., 4.])\n",
            "Indices: tensor([0, 2, 1, 2])\n",
            "scatter_add_1d result: tensor([1., 3., 6., 0.])\n",
            "Expected: [1.0, 3.0, 6.0, 0.0] (values at index 2 are summed: 2.0 + 4.0 = 6.0)\n"
          ]
        }
      ],
      "source": [
        "def scatter_add_1d(\n",
        "    values: torch.Tensor, indices: torch.Tensor, size: int\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Sum `values` into an output vector at positions `indices`.\n",
        "\n",
        "    Shapes:\n",
        "    - values: (N,)\n",
        "    - indices: (N,) integer indices in [0, size)\n",
        "    Return:\n",
        "    - out: (size,) with same dtype and device as values\n",
        "\n",
        "    Requirement:\n",
        "    - no Python loops\n",
        "    \"\"\"\n",
        "    # Create output tensor of zeros with the specified size\n",
        "    out = torch.zeros(size, dtype=values.dtype, device=values.device)\n",
        "    # Use scatter_add_ to accumulate values at the specified indices\n",
        "    out.scatter_add_(0, indices, values)\n",
        "    return out\n",
        "\n",
        "# Quick check for scatter_add_1d\n",
        "values = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "indices = torch.tensor([0, 2, 1, 2])\n",
        "result = scatter_add_1d(values, indices, size=4)\n",
        "print(f\"Values: {values}\")\n",
        "print(f\"Indices: {indices}\")\n",
        "print(f\"scatter_add_1d result: {result}\")\n",
        "print(f\"Expected: [1., 3., 6., 0.] (values at index 2 are summed: 2.0 + 4.0 = 6.0)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "a772cc7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:\n",
            "tensor([[0, 1, 2, 1],\n",
            "        [2, 2, 0, 1]])\n",
            "Vocab size: 3\n",
            "Batched token histogram:\n",
            "tensor([[1, 2, 1],\n",
            "        [1, 1, 2]])\n",
            "Expected: [[1, 2, 1], [1, 1, 2]] (batch 0: token 0 appears 1x, token 1 appears 2x, token 2 appears 1x)\n"
          ]
        }
      ],
      "source": [
        "def batched_token_histogram(tokens: torch.Tensor, vocab_size: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Count token occurrences per batch item.\n",
        "\n",
        "    Shapes:\n",
        "    - tokens: (B, T) int64\n",
        "    Return:\n",
        "    - counts: (B, vocab_size) where counts[b, v] = number of times token v appears in tokens[b]\n",
        "\n",
        "    Requirements:\n",
        "    - No Python loops over B or T.\n",
        "    \"\"\"\n",
        "    B, T = tokens.shape\n",
        "    # Create output tensor of zeros with shape (B, vocab_size)\n",
        "    counts = torch.zeros(B, vocab_size, dtype=torch.long, device=tokens.device)\n",
        "\n",
        "    # Create batch indices for scatter_add_\n",
        "    # batch_indices: (B, T) where each row is [0, 0, ..., 0], [1, 1, ..., 1], etc.\n",
        "    batch_indices = torch.arange(B, device=tokens.device).unsqueeze(1).expand(B, T)\n",
        "\n",
        "    # Flatten everything for scatter_add_\n",
        "    batch_flat = batch_indices.reshape(-1)  # (B*T,)\n",
        "    tokens_flat = tokens.reshape(-1)  # (B*T,)\n",
        "    ones = torch.ones(B * T, dtype=torch.long, device=tokens.device)\n",
        "\n",
        "    # Use scatter_add_ to count occurrences\n",
        "    # We need to convert 2D indices (batch, token) into 1D indices\n",
        "    flat_indices = batch_flat * vocab_size + tokens_flat\n",
        "    counts_flat = counts.reshape(-1)\n",
        "    counts_flat.scatter_add_(0, flat_indices, ones)\n",
        "\n",
        "    return counts.reshape(B, vocab_size)\n",
        "\n",
        "# Quick check for batched_token_histogram\n",
        "tokens = torch.tensor([[0, 1, 2, 1], [2, 2, 0, 1]])\n",
        "vocab_size = 3\n",
        "result = batched_token_histogram(tokens, vocab_size)\n",
        "print(f\"Tokens:\\n{tokens}\")\n",
        "print(f\"Vocab size: {vocab_size}\")\n",
        "print(f\"Batched token histogram:\\n{result}\")\n",
        "print(f\"Expected: [[1, 2, 1], [1, 1, 2]] (batch 0: token 0 appears 1x, token 1 appears 2x, token 2 appears 1x)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "64c263a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Mask:\n",
            "tensor([[ True,  True, False],\n",
            "        [ True, False, False]])\n",
            "Masked mean (dim=1):\n",
            "tensor([1.5000, 4.0000])\n",
            "Expected: [1.5, 4.0] (batch 0: (1+2)/2=1.5, batch 1: 4/1=4.0)\n",
            "\n",
            "Masked mean with some all-False rows:\n",
            "tensor([0., 5.])\n",
            "Expected: [0.0, 5.0] (batch 0: all masked out -> 0, batch 1: (4+5+6)/3=5.0)\n"
          ]
        }
      ],
      "source": [
        "def masked_mean(x: torch.Tensor, mask: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Mean over `dim` considering only mask==True entries.\n",
        "\n",
        "    Convention:\n",
        "    - mask: bool tensor broadcastable to x\n",
        "    - mask==True means \"keep this entry\"\n",
        "\n",
        "    Return: same shape as x.mean(dim=dim)\n",
        "\n",
        "    Requirements:\n",
        "    - Avoid division by zero: if all mask are False along `dim`, define mean as 0.\n",
        "    \"\"\"\n",
        "    # Convert mask to float for multiplication\n",
        "    mask_float = mask.float()\n",
        "\n",
        "    # Zero out entries where mask is False\n",
        "    masked_x = x * mask_float\n",
        "\n",
        "    # Sum the masked values along the specified dimension\n",
        "    masked_sum = masked_x.sum(dim=dim)\n",
        "\n",
        "    # Count how many True entries along the dimension\n",
        "    count = mask_float.sum(dim=dim)\n",
        "\n",
        "    # Avoid division by zero: where count is 0, set it to 1 (result will be 0/1 = 0)\n",
        "    count = torch.where(count == 0, torch.ones_like(count), count)\n",
        "\n",
        "    # Compute the mean\n",
        "    result = masked_sum / count\n",
        "\n",
        "    return result\n",
        "\n",
        "# Quick check for masked_mean\n",
        "x = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "mask = torch.tensor([[True, True, False], [True, False, False]])\n",
        "result_dim1 = masked_mean(x, mask, dim=1)\n",
        "print(f\"Input x:\\n{x}\")\n",
        "print(f\"Mask:\\n{mask}\")\n",
        "print(f\"Masked mean (dim=1):\\n{result_dim1}\")\n",
        "print(f\"Expected: [1.5, 4.0] (batch 0: (1+2)/2=1.5, batch 1: 4/1=4.0)\")\n",
        "\n",
        "# Test with all False mask\n",
        "mask_all_false = torch.tensor([[False, False, False], [True, True, True]])\n",
        "result_all_false = masked_mean(x, mask_all_false, dim=1)\n",
        "print(f\"\\nMasked mean with some all-False rows:\\n{result_all_false}\")\n",
        "print(f\"Expected: [0.0, 5.0] (batch 0: all masked out -> 0, batch 1: (4+5+6)/3=5.0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63636e30",
      "metadata": {},
      "source": [
        "## Einsum warmup\n",
        "Now that you’re comfortable with shapes and broadcasting, we’ll introduce `torch.einsum`, a concise way to express tensor operations by explicitly naming axes and summing over repeated indices.\n",
        "\n",
        "### The idea\n",
        "You describe each input tensor by labeling its dimensions with letters, e.g.\n",
        "- `x: (B, T, D)` → `\"btd\"`\n",
        "- `W: (D, H)`    → `\"dh\"`\n",
        "\n",
        "Then you tell einsum what output labels you want:\n",
        "- `\"btd,dh->bth\"`\n",
        "\n",
        "### Rules of einsum\n",
        "1) **Same letter = same axis** (must match in size, except broadcastable size-1).\n",
        "2) **Repeated letters are summed over** (a “contraction”).\n",
        "3) **Letters that appear in the output are kept** (in that order).\n",
        "4) You can **reorder axes** just by changing the output label order.\n",
        "\n",
        "### Tiny cheat sheet\n",
        "- Sum over an axis: `\"btd->bt\"` (sums over `d`)\n",
        "- Transpose: `\"ij->ji\"`\n",
        "- Dot product: `\"d,d->\"` or batched `\"btd,btd->bt\"`\n",
        "- Matrix multiply: `\"ik,kj->ij\"`\n",
        "- Batched matmul: `\"bij,bjk->bik\"`\n",
        "- Outer product: `\"i,j->ij\"`\n",
        "\n",
        "### How to derive an einsum (recommended workflow)\n",
        "1) Write down shapes with named axes (e.g. `q: b h t d`, `k: b h s d`).\n",
        "2) Decide which axes you want to **sum over** (give them the same letter in both inputs).\n",
        "3) Decide which axes you want to **keep** in the output (write them after `->`).\n",
        "\n",
        "In this section, you’ll use einsum to implement building blocks that show up in attention:\n",
        "- linear projections (`x @ W`)\n",
        "- dot products\n",
        "- attention score matrices (`QKᵀ`)\n",
        "- applying attention weights (`softmax(scores) @ V`)\n",
        "\n",
        "NOTE: For these exercises you are required to use `torch.einsum` not `matmul` (we check). You are also not required to understand the attention mechanism at this point and the exercises are sovable without. It is good however, to remember the implementations in this exercise for future implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "5b5b2bca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x:\n",
            "tensor([[[-1.2894, -0.6417,  1.0130,  1.5455],\n",
            "         [-0.4208,  1.7069, -0.8938,  0.5079],\n",
            "         [ 1.4580,  1.1857,  1.1367,  0.5306]],\n",
            "\n",
            "        [[-0.5157, -0.1709, -2.5697,  1.0639],\n",
            "         [ 0.0086,  1.5308, -0.0896, -0.6444],\n",
            "         [-0.2858,  1.1921, -0.0117, -1.0445]]])\n",
            "Weight W:\n",
            "tensor([[ 0.3487,  0.2342,  0.2083,  1.3587, -0.0191],\n",
            "        [ 0.1549,  0.1116, -2.0587,  0.5292, -0.2444],\n",
            "        [ 0.3462,  0.0850, -0.7461,  2.7192,  0.5329],\n",
            "        [-0.8640, -0.4612,  1.9042,  0.9572,  1.3263]])\n",
            "Output y:\n",
            "tensor([[[-1.5336, -1.0003,  3.2398,  2.1423,  2.7710],\n",
            "         [-0.6306, -0.2183, -1.9676, -1.6126, -0.2118],\n",
            "         [ 0.6272,  0.3257, -1.9750,  6.2074,  0.9919]],\n",
            "\n",
            "        [[-2.0152, -0.8490,  4.1877, -6.7604,  0.0933],\n",
            "         [ 0.7659,  0.4624, -4.3099, -0.0388, -1.2767],\n",
            "         [ 0.9834,  0.5469, -4.4941, -0.7890, -1.6774]]])\n"
          ]
        }
      ],
      "source": [
        "def einsum_linear_btd_dh_to_bth(x: torch.Tensor, W: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Linear projection using einsum.\n",
        "\n",
        "    Shapes:\n",
        "    - x: (B, T, D)\n",
        "    - W: (D, H)\n",
        "    Return:\n",
        "    - y: (B, T, H)\n",
        "    \"\"\"\n",
        "    # x has shape (B, T, D) -> label as \"btd\"\n",
        "    # W has shape (D, H) -> label as \"dh\"\n",
        "    # We want to sum over D (the shared dimension)\n",
        "    # Output should be (B, T, H) -> label as \"bth\"\n",
        "    y = torch.einsum(\"btd,dh->bth\", x, W)\n",
        "\n",
        "    return y\n",
        "\n",
        "# Example usage\n",
        "B, T, D, H = 2, 3, 4, 5\n",
        "x = torch.randn(B, T, D)\n",
        "W = torch.randn(D, H)\n",
        "y = einsum_linear_btd_dh_to_bth(x, W)\n",
        "print(f\"Input x:\\n{x}\")\n",
        "print(f\"Weight W:\\n{W}\")\n",
        "print(f\"Output y:\\n{y}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "62873ad9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input x shape: torch.Size([2, 3, 4])\n",
            "Input x : \n",
            "tensor([[[ 0.9832,  0.2583,  0.7991, -0.4400],\n",
            "         [-0.4836,  1.7729, -1.6043,  0.6841],\n",
            "         [-1.3693, -0.2251,  0.1797, -1.8506]],\n",
            "\n",
            "        [[-0.7692, -1.0373, -0.7382, -0.0743],\n",
            "         [ 0.3102, -0.9968,  0.9680, -0.6660],\n",
            "         [-0.4834, -0.5480, -0.4567, -0.4177]]])\n",
            "\n",
            "Input y shape: torch.Size([2, 3, 4])\n",
            "Input y: \n",
            "tensor([[[ 1.3701, -0.4849,  0.2198,  0.0501],\n",
            "         [ 0.1318,  2.3606, -0.4911, -0.2938],\n",
            "         [ 0.8714, -0.8666,  0.5537, -0.5355]],\n",
            "\n",
            "        [[ 1.1904, -0.3813, -1.4756, -0.7867],\n",
            "         [ 0.6286,  0.7151, -0.9377, -0.2933],\n",
            "         [ 1.2918, -0.1248, -0.7089,  0.3701]]])\n",
            "\n",
            "Output dots shape: torch.Size([2, 3])\n",
            "Output dots:\n",
            "tensor([[ 1.3754,  4.7083,  0.0923],\n",
            "        [ 0.6275, -1.2302, -0.3869]])\n"
          ]
        }
      ],
      "source": [
        "def einsum_pairwise_dot(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Pairwise dot product between x and y.\n",
        "\n",
        "    Shapes:\n",
        "    - x: (B, T, D)\n",
        "    - y: (B, T, D)\n",
        "    Return:\n",
        "    - dots: (B, T) where dots[b,t] = dot(x[b,t], y[b,t])\n",
        "    \"\"\"\n",
        "    # x has shape (B, T, D) -> label as \"btd\"\n",
        "    # y has shape (B, T, D) -> label as \"btd\"\n",
        "    # We want to sum over D (the shared dimension for dot product)\n",
        "    # Output should be (B, T) -> label as \"bt\"\n",
        "    dots = torch.einsum(\"btd,btd->bt\", x, y)\n",
        "\n",
        "    return dots\n",
        "\n",
        "# Example\n",
        "B, T, D = 2, 3, 4\n",
        "x = torch.randn(B, T, D)\n",
        "y = torch.randn(B, T, D)\n",
        "dots = einsum_pairwise_dot(x, y)\n",
        "print(f\"Input x shape: {x.shape}\")\n",
        "print(f\"Input x : \\n{x}\\n\")\n",
        "print(f\"Input y shape: {y.shape}\")\n",
        "print(f\"Input y: \\n{y}\\n\")\n",
        "print(f\"Output dots shape: {dots.shape}\")\n",
        "print(f\"Output dots:\\n{dots}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "3284ba6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query q shape: torch.Size([2, 3, 4, 5])\n",
            "Key k shape: torch.Size([2, 3, 4, 5])\n",
            "Scores shape: torch.Size([2, 3, 4, 4])\n",
            "Scores:\n",
            "tensor([[[[-2.1125, -1.2437, -1.3071,  0.7863],\n",
            "          [-1.2806,  2.0429, -2.7935, -2.8358],\n",
            "          [ 1.9617, -3.2367,  1.3090, -0.4283],\n",
            "          [-4.0495, -0.6375, -2.5105,  5.6523]],\n",
            "\n",
            "         [[ 1.2895,  0.0360,  2.2279, -0.6961],\n",
            "          [ 0.6300, -1.7143,  2.7321,  0.4183],\n",
            "          [-1.7585, -0.3796, -2.4269, -1.2258],\n",
            "          [ 0.6286,  1.4669,  1.3121, -0.2500]],\n",
            "\n",
            "         [[-0.8792,  2.6554,  2.1585, -3.6343],\n",
            "          [-0.4860, -4.2922, -3.5201, -1.7220],\n",
            "          [-0.2678, -2.5024, -0.9727, -2.7100],\n",
            "          [ 1.6127,  4.1782,  2.2001,  2.7633]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4462, -0.8451,  1.9368, -4.6323],\n",
            "          [ 3.3634,  0.1512,  2.2604, -0.7003],\n",
            "          [ 2.2317,  0.3510, -0.2277,  2.8992],\n",
            "          [ 1.4594, -2.1479,  0.7099,  1.3697]],\n",
            "\n",
            "         [[ 2.8657, -0.2721,  0.9616,  0.9559],\n",
            "          [ 0.6156, -0.8614, -1.1999,  0.8588],\n",
            "          [-2.7099,  0.0393, -2.3702, -0.8118],\n",
            "          [-0.1459,  5.0249,  3.0051,  1.8579]],\n",
            "\n",
            "         [[ 3.4569,  0.9267,  4.0224, -0.6219],\n",
            "          [ 1.9424,  2.7388,  2.2266,  0.8086],\n",
            "          [-0.7213, -2.4071, -2.2978, -0.9729],\n",
            "          [-3.5481,  2.6315,  0.8082, -0.3599]]]])\n",
            "\n",
            "Verification - manual dot product for first batch, first head, first query:\n",
            "Manual: -2.112490177154541\n",
            "Einsum: -2.112490177154541\n"
          ]
        }
      ],
      "source": [
        "def einsum_qk_scores(q: torch.Tensor, k: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute attention scores QK^T using einsum.\n",
        "\n",
        "    Shapes:\n",
        "    - q: (B, H, T, Dh)\n",
        "    - k: (B, H, T, Dh)\n",
        "    Return:\n",
        "    - scores: (B, H, T, T) where scores[b,h,i,j] = dot(q[b,h,i], k[b,h,j])\n",
        "    \"\"\"\n",
        "    # q has shape (B, H, T, Dh) -> label as \"bhtd\"\n",
        "    # k has shape (B, H, T, Dh) -> label as \"bhsd\" (use 's' for the second T dimension)\n",
        "    # We want to compute dot product over Dh dimension\n",
        "    # Output should be (B, H, T, T) -> label as \"bhts\"\n",
        "    scores = torch.einsum(\"bhtd,bhsd->bhts\", q, k)\n",
        "\n",
        "    return scores\n",
        "\n",
        "# Example usage\n",
        "B, H, T, Dh = 2, 3, 4, 5\n",
        "q = torch.randn(B, H, T, Dh)\n",
        "k = torch.randn(B, H, T, Dh)\n",
        "scores = einsum_qk_scores(q, k)\n",
        "print(f\"Query q shape: {q.shape}\")\n",
        "print(f\"Key k shape: {k.shape}\")\n",
        "print(f\"Scores shape: {scores.shape}\")\n",
        "print(f\"Scores:\\n{scores}\")\n",
        "print(f\"\\nVerification - manual dot product for first batch, first head, first query:\")\n",
        "manual_score = torch.sum(q[0, 0, 0, :] * k[0, 0, 0, :])\n",
        "print(f\"Manual: {manual_score}\")\n",
        "print(f\"Einsum: {scores[0, 0, 0, 0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e89345b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def einsum_apply_attention(weights: torch.Tensor, v: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Apply attention weights to values using einsum.\n",
        "\n",
        "    Shapes:\n",
        "    - weights: (B, H, T, T)\n",
        "    - v:       (B, H, T, Dh)\n",
        "    Return:\n",
        "    - out:     (B, H, T, Dh) where out[b,h,i] = sum_j weights[b,h,i,j] * v[b,h,j]\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de3519de",
      "metadata": {},
      "source": [
        "## Attention Fundamentals\n",
        "This exercise introduces some building blocks of the attention mechanism which we will encounter extensively throughout the course. It's not yet required for you to fully understand the mechanism to implement the exercises. However, it's good to remember these building blocks for the future. \n",
        "\n",
        "To complete the exercises you should familiarize yourself with these topics:\n",
        "- Stable softmax read: https://jaykmody.com/blog/stable-softmax/\n",
        "- Masking: typically this means setting masked logits to -inf *before* softmax.\n",
        "- For attention: causal masks are upper-triangular (no attending to the future)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6427a99b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stable_softmax(x: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Numerically stable softmax along `dim`.\n",
        "\n",
        "    Requirements:\n",
        "    - Must not overflow for large values in x.\n",
        "    - Output sums to 1 along `dim`.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38475c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "def masked_fill_tensor(x: torch.Tensor, mask: torch.Tensor, value: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Return a copy of x where positions with mask == True are replaced by `value`.\n",
        "\n",
        "    Requirements:\n",
        "    - mask must be broadcastable to x.\n",
        "    - do NOT modify x in-place.\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70896023",
      "metadata": {},
      "outputs": [],
      "source": [
        "def masked_softmax(x: torch.Tensor, mask: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Softmax over x with a boolean mask.\n",
        "\n",
        "    Convention:\n",
        "    - mask == True means \"invalid and must receive probability 0\".\n",
        "    - Do masking before softmax (i.e., set invalid logits to a large negative).”\n",
        "\n",
        "    Requirements:\n",
        "    - Must be numerically stable.\n",
        "    - Output must be exactly 0 where mask==True.\n",
        "    - If all entries are masked along `dim`, return all zeros along `dim`.\n",
        "    - You may reuse functions you implemented above.\n",
        "    \"\"\"\n",
        "    # TODO: implement using masked_fill_tensor + stable_softmax\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6de9438",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_causal_mask(T: int, device: torch.device | str | None = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Create a causal (future-masking) boolean mask of shape (T, T).\n",
        "\n",
        "    Convention:\n",
        "    - mask[i, j] == True  => position (i attends to j) is NOT allowed (j is in the future)\n",
        "    - mask[i, j] == False => allowed\n",
        "\n",
        "    So this is an upper-triangular mask above the diagonal.\n",
        "\n",
        "    Return:\n",
        "    - mask: boolean tensor on the specified device\n",
        "\n",
        "    Example (T=4):\n",
        "        [[F, T, T, T],\n",
        "         [F, F, T, T],\n",
        "         [F, F, F, T],\n",
        "         [F, F, F, F]]\n",
        "    \"\"\"\n",
        "    # TODO: implement\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc09578b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_causal_mask(attn_logits: torch.Tensor, value: float = -1e9) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Apply a causal mask to attention logits.\n",
        "\n",
        "    Expected shapes:\n",
        "    - attn_logits: (..., T, T)\n",
        "\n",
        "    Returns:\n",
        "    - masked logits (same shape) where masked positions have been set to `value`.\n",
        "\n",
        "    Notes:\n",
        "    - Create a causal mask for the final two dims.\n",
        "    - Broadcast it across leading dims.\n",
        "    - You may reuse functions declared above.\n",
        "    \"\"\"\n",
        "    # TODO: implement using make_causal_mask + masked_fill_tensor\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb39ba4",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "robot_learning_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
